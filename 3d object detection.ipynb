{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84342b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422b299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ultralytics/ultralytics.git\n",
      "  Cloning https://github.com/ultralytics/ultralytics.git to c:\\users\\satya\\appdata\\local\\temp\\pip-req-build-vhe5_tfp\n",
      "  Resolved https://github.com/ultralytics/ultralytics.git to commit 60041014a8c9dc7f9621e5d91952370443417975\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (3.5.2)\n",
      "Requirement already satisfied: numpy>=1.22.2 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (1.22.4)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (4.8.0.74)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (9.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (1.8.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (2.1.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (0.16.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (4.65.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (1.1.4)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (0.11.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (5.9.1)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics==8.0.221) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.221) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.221) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.221) (1.4.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.221) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.221) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics==8.0.221) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.1.4->ultralytics==8.0.221) (2022.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.221) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.221) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.221) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.23.0->ultralytics==8.0.221) (2022.6.15)\n",
      "Requirement already satisfied: filelock in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.221) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.221) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.221) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.221) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.221) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics==8.0.221) (2023.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm>=4.64.0->ultralytics==8.0.221) (0.4.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.0.221) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics==8.0.221) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics==8.0.221) (1.3.0)\n",
      "Building wheels for collected packages: ultralytics\n",
      "  Building wheel for ultralytics (setup.py): started\n",
      "  Building wheel for ultralytics (setup.py): finished with status 'done'\n",
      "  Created wheel for ultralytics: filename=ultralytics-8.0.221-py3-none-any.whl size=655222 sha256=95c078119b6eee0de55a4568d1033866262bfad92a388a74264e3ff8b99064e7\n",
      "  Stored in directory: C:\\Users\\satya\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-2b8irefx\\wheels\\ad\\b6\\d9\\733e1c16ac5679bc39a0101d698a65224d06746d9f2c5c30b6\n",
      "Successfully built ultralytics\n",
      "Installing collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.0.214\n",
      "    Uninstalling ultralytics-8.0.214:\n",
      "      Successfully uninstalled ultralytics-8.0.214\n",
      "Successfully installed ultralytics-8.0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ultralytics/ultralytics.git 'C:\\Users\\satya\\AppData\\Local\\Temp\\pip-req-build-vhe5_tfp'\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ultralytics/ultralytics.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c73ff87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.23M/6.23M [00:05<00:00, 1.28MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x448 1 person, 1 tie, 778.2ms\n",
      "Speed: 34.0ms preprocess, 778.2ms inference, 33.2ms postprocess per image at shape (1, 3, 640, 448)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3d object detection using image\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "img = cv2.imread('nagendra.jpeg')\n",
    "\n",
    "def rescaleframe(frame,scale=0.75):\n",
    "    width = int (frame.shape[1]*scale)\n",
    "    height = int(frame.shape[0]*scale)\n",
    "    \n",
    "    dimensions = (width,height)\n",
    "    return cv2.resize(frame,dimensions, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "resize = rescaleframe(img, scale=0.5)\n",
    "\n",
    "\n",
    "results = model(resize,show = True)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "751dd3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cvzone in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cvzone) (4.8.0.74)\n",
      "Requirement already satisfied: numpy in c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cvzone) (1.22.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\satya\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install cvzone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c69df03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 2 persons, 716.6ms\n",
      "Speed: 24.5ms preprocess, 716.6ms inference, 20.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 574.6ms\n",
      "Speed: 13.4ms preprocess, 574.6ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 553.8ms\n",
      "Speed: 10.0ms preprocess, 553.8ms inference, 11.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 557.5ms\n",
      "Speed: 8.6ms preprocess, 557.5ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 633.9ms\n",
      "Speed: 9.0ms preprocess, 633.9ms inference, 10.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 615.5ms\n",
      "Speed: 8.0ms preprocess, 615.5ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 499.4ms\n",
      "Speed: 9.0ms preprocess, 499.4ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 512.5ms\n",
      "Speed: 9.6ms preprocess, 512.5ms inference, 10.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 480.2ms\n",
      "Speed: 7.0ms preprocess, 480.2ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 488.3ms\n",
      "Speed: 9.5ms preprocess, 488.3ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 482.9ms\n",
      "Speed: 6.0ms preprocess, 482.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 511.7ms\n",
      "Speed: 8.0ms preprocess, 511.7ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 490.4ms\n",
      "Speed: 8.0ms preprocess, 490.4ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 476.7ms\n",
      "Speed: 7.5ms preprocess, 476.7ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 488.4ms\n",
      "Speed: 8.0ms preprocess, 488.4ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 501.9ms\n",
      "Speed: 9.0ms preprocess, 501.9ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 tie, 604.1ms\n",
      "Speed: 7.1ms preprocess, 604.1ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 489.6ms\n",
      "Speed: 9.0ms preprocess, 489.6ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 500.1ms\n",
      "Speed: 7.1ms preprocess, 500.1ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 498.3ms\n",
      "Speed: 9.1ms preprocess, 498.3ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 481.0ms\n",
      "Speed: 8.0ms preprocess, 481.0ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 487.1ms\n",
      "Speed: 9.5ms preprocess, 487.1ms inference, 8.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 482.1ms\n",
      "Speed: 9.0ms preprocess, 482.1ms inference, 7.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 503.2ms\n",
      "Speed: 8.0ms preprocess, 503.2ms inference, 12.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 490.1ms\n",
      "Speed: 8.5ms preprocess, 490.1ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 490.2ms\n",
      "Speed: 8.2ms preprocess, 490.2ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 491.1ms\n",
      "Speed: 9.4ms preprocess, 491.1ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 493.8ms\n",
      "Speed: 8.0ms preprocess, 493.8ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 480.9ms\n",
      "Speed: 9.2ms preprocess, 480.9ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 489.1ms\n",
      "Speed: 8.7ms preprocess, 489.1ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 492.3ms\n",
      "Speed: 8.7ms preprocess, 492.3ms inference, 8.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 491.1ms\n",
      "Speed: 7.3ms preprocess, 491.1ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 493.3ms\n",
      "Speed: 10.0ms preprocess, 493.3ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 483.6ms\n",
      "Speed: 8.0ms preprocess, 483.6ms inference, 10.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 481.3ms\n",
      "Speed: 9.1ms preprocess, 481.3ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 487.8ms\n",
      "Speed: 9.0ms preprocess, 487.8ms inference, 8.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 509.3ms\n",
      "Speed: 9.0ms preprocess, 509.3ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 536.5ms\n",
      "Speed: 7.6ms preprocess, 536.5ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 616.0ms\n",
      "Speed: 8.4ms preprocess, 616.0ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 533.3ms\n",
      "Speed: 8.0ms preprocess, 533.3ms inference, 10.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 550.8ms\n",
      "Speed: 9.8ms preprocess, 550.8ms inference, 9.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 cell phone, 607.9ms\n",
      "Speed: 9.8ms preprocess, 607.9ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 584.9ms\n",
      "Speed: 9.1ms preprocess, 584.9ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 619.9ms\n",
      "Speed: 10.8ms preprocess, 619.9ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 589.0ms\n",
      "Speed: 9.8ms preprocess, 589.0ms inference, 13.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 600.8ms\n",
      "Speed: 12.0ms preprocess, 600.8ms inference, 11.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 598.6ms\n",
      "Speed: 9.4ms preprocess, 598.6ms inference, 11.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 1 remote, 578.7ms\n",
      "Speed: 9.0ms preprocess, 578.7ms inference, 10.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 564.7ms\n",
      "Speed: 8.4ms preprocess, 564.7ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 593.3ms\n",
      "Speed: 9.0ms preprocess, 593.3ms inference, 10.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 662.6ms\n",
      "Speed: 10.4ms preprocess, 662.6ms inference, 14.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 592.8ms\n",
      "Speed: 9.0ms preprocess, 592.8ms inference, 11.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 551.6ms\n",
      "Speed: 8.3ms preprocess, 551.6ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 519.1ms\n",
      "Speed: 7.6ms preprocess, 519.1ms inference, 10.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 585.1ms\n",
      "Speed: 7.0ms preprocess, 585.1ms inference, 10.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 559.1ms\n",
      "Speed: 10.0ms preprocess, 559.1ms inference, 8.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 556.7ms\n",
      "Speed: 9.0ms preprocess, 556.7ms inference, 10.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 560.3ms\n",
      "Speed: 8.1ms preprocess, 560.3ms inference, 9.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# dimensions like width and height of the video frame\n",
    "cap.set(3, 1280)\n",
    "cap.set(4, 720)\n",
    "\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "\n",
    "classNames = [\"person\",\"bicycle\",\"car\",\"motorbike\",\"aeroplane\",\"bus\",\"train\",\"truck\",\"boat\",\n",
    "              \"traffic light\",\"fire hydrant\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\",\"elephant\",\"bear\",\"zebra\",\"giraffe\",\"backpack\",\"umbrella\",\n",
    "              \"handbag\",\"tie\",\"suitcase\",\"frisbee\",\"skis\",\"snowboard\",\"sports ball\",\"kite\",\"baseball bat\",\n",
    "             \"baseball glove\",\"skateboard\",\"surfboard\",\"tennis racket\",\"bottle\",\"wine glass\",\"cup\",\n",
    "             \"fork\",\"knife\",\"spoon\",\"bowl\",\"banana\",\"apple\",\"sandwich\",\"orange\",\"broccoli\",\n",
    "              \"carrot\",\"hot dog\",\"pizza\",\"donut\",\"cake\",\"chair\",\"sofa\",\"pottedplant\",\"bed\",\n",
    "             \"diningtable\",\"toilet\",\"tvmonitor\",\"laptop\",\"mouse\",\"remote\",\"keyboard\",\"cell phone\",\n",
    "             \"microwave\",\"oven\",\"toaster\",\"sink\",\"refrigerator\",\"book\",\"clock\",\"vase\",\"scissors\",\n",
    "             \"teddy bear\",\"hair drier\",\"toothbrush\"\n",
    "             ]\n",
    "\n",
    "def rescaleframe(frame,scale=0.75):\n",
    "    width = int (frame.shape[1]*scale)\n",
    "    height = int(frame.shape[0]*scale)\n",
    "    \n",
    "    dimensions = (width,height)\n",
    "    return cv2.resize(frame,dimensions, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream = True)\n",
    "    img_resized = rescaleframe(img,scale=1)\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1,y1,x2,y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "           \n",
    "            w, h = x2-x1, y2-y1\n",
    "            cvzone.cornerRect(img_resized,(x1,y1,w,h))\n",
    "            \n",
    "            \n",
    "            conf = math.ceil((box.conf[0]*100))/100\n",
    "          \n",
    "            \n",
    "            \n",
    "            cls = int(box.cls[0])\n",
    "            cvzone.putTextRect(img_resized,f'{classNames[cls]} {conf}',(max(0,x1),max(35,y1)))\n",
    "            \n",
    "            \n",
    "    cv2.imshow('image',img_resized)\n",
    "  \n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        break   \n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68df8248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 11 cars, 538.7ms\n",
      "Speed: 14.0ms preprocess, 538.7ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 498.2ms\n",
      "Speed: 14.0ms preprocess, 498.2ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 590.7ms\n",
      "Speed: 14.0ms preprocess, 590.7ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 510.6ms\n",
      "Speed: 14.0ms preprocess, 510.6ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 451.5ms\n",
      "Speed: 11.6ms preprocess, 451.5ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 453.3ms\n",
      "Speed: 11.0ms preprocess, 453.3ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 455.5ms\n",
      "Speed: 11.0ms preprocess, 455.5ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 460.4ms\n",
      "Speed: 12.0ms preprocess, 460.4ms inference, 10.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 463.0ms\n",
      "Speed: 13.3ms preprocess, 463.0ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 466.4ms\n",
      "Speed: 13.0ms preprocess, 466.4ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 422.7ms\n",
      "Speed: 16.0ms preprocess, 422.7ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 10 cars, 499.4ms\n",
      "Speed: 11.6ms preprocess, 499.4ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 530.9ms\n",
      "Speed: 14.4ms preprocess, 530.9ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 448.5ms\n",
      "Speed: 13.0ms preprocess, 448.5ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 429.0ms\n",
      "Speed: 12.0ms preprocess, 429.0ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 448.3ms\n",
      "Speed: 11.0ms preprocess, 448.3ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 868.2ms\n",
      "Speed: 14.4ms preprocess, 868.2ms inference, 11.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 13 cars, 508.4ms\n",
      "Speed: 12.4ms preprocess, 508.4ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 535.1ms\n",
      "Speed: 12.3ms preprocess, 535.1ms inference, 11.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 12 cars, 482.8ms\n",
      "Speed: 13.8ms preprocess, 482.8ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 11 cars, 430.2ms\n",
      "Speed: 12.0ms preprocess, 430.2ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import cvzone\n",
    "import math\n",
    "\n",
    "# cap = cv2.VideoCapture(\"cars.mp4\")\n",
    "cap = cv2.VideoCapture(\"cars.mp4\")\n",
    "\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "\n",
    "classNames = [\"person\",\"bicycle\",\"car\",\"motorbike\",\"aeroplane\",\"bus\",\"train\",\"truck\",\"boat\",\n",
    "              \"traffic light\",\"fire hydrant\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\n",
    "              \"dog\", \"horse\", \"sheep\", \"cow\",\"elephant\",\"bear\",\"zebra\",\"giraffe\",\"backpack\",\"umbrella\",\n",
    "              \"handbag\",\"tie\",\"suitcase\",\"frisbee\",\"skis\",\"snowboard\",\"sports ball\",\"kite\",\"baseball bat\",\n",
    "             \"baseball glove\",\"skateboard\",\"surfboard\",\"tennis racket\",\"bottle\",\"wine glass\",\"cup\",\n",
    "             \"fork\",\"knife\",\"spoon\",\"bowl\",\"banana\",\"apple\",\"sandwich\",\"orange\",\"broccoli\",\n",
    "              \"carrot\",\"hot dog\",\"pizza\",\"donut\",\"cake\",\"chair\",\"sofa\",\"pottedplant\",\"bed\",\n",
    "             \"diningtable\",\"toilet\",\"tvmonitor\",\"laptop\",\"mouse\",\"remote\",\"keyboard\",\"cell phone\",\n",
    "             \"microwave\",\"oven\",\"toaster\",\"sink\",\"refrigerator\",\"book\",\"clock\",\"vase\",\"scissors\",\n",
    "             \"teddy bear\",\"hair drier\",\"toothbrush\"\n",
    "             ]\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    results = model(img, stream = True)\n",
    "\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "        for box in boxes:\n",
    "            x1,y1,x2,y2 = box.xyxy[0]\n",
    "            x1,y1,x2,y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "           \n",
    "            w, h = x2-x1, y2-y1\n",
    "            cvzone.cornerRect(img,(x1,y1,w,h))\n",
    "            \n",
    "            \n",
    "            conf = math.ceil((box.conf[0]*100))/100\n",
    "          \n",
    "            \n",
    "            \n",
    "            cls = int(box.cls[0])\n",
    "            cvzone.putTextRect(img,f'{classNames[cls]} {conf}',(max(0,x1),max(35,y1)),scale=0.7,thickness=1)\n",
    "            \n",
    "            \n",
    "    cv2.imshow('image',img)\n",
    "  \n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        break   \n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba980801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
